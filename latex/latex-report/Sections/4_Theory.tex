%================================================================
\section{Theory}\label{sec:Theory}
%================================================================

%----------------------------------------------------------------
\subsection{Draft}
%---------------------------------------------------------------- 

%----------------------------------------------------------------
\subsubsection*{The System}
%---------------------------------------------------------------- 

The system under investigation is a trapped Bose gas of alkali atoms, specifically $^{87}$Rb. A key feature of alkali systems is that they are dilute, i.e., the volume per atom is much larger than the volume of the atom. The average distance between the atoms is thus much larger than the range of the inter-atomic interaction, and the physics is dominated by two-body collisions. 

In order to model the Bose gas, we consider atoms trapped in either a spherical (S) or elliptical (E) harmonic oscillator trap: 

\begin{equation}\label{eq:Vtrap}
    V_\mathrm{trap} \qty(\bm{r}) = 
    \begin{cases}
        \frac{1}{2} m \omega_\mathrm{ho}^2 r^2 \quad &\text{(S)}
        \\
        \frac{1}{2} m \qty[\omega_\mathrm{ho}^2 \qty(x^2 + y^2) + \omega_z^2 z^2] \quad &\text{(E)}
    \end{cases}
\end{equation}

Here, $\omega_\mathrm{ho}^2$ defines the trap potential strength. In the case of an elliptical trap, $\omega_\mathrm{ho}=\omega_\perp$ is the trap frequency in the $xy$ plane and $\omega_z$ the frequency in the $z$ direction. 

The atoms are modeled as hard spheres of diameter proportional to the scattering length $a$ that cannot overlap in space, mimicking the strong repulsion that atoms experience at close distances. The two-body interaction between atoms is thus described by the following pairwise, repulsive potential:

\begin{equation}\label{eq:Vint}
    V_\mathrm{int} \qty(\abs{\bm{r}_i - \bm{r}_j}) = 
    \begin{cases}
        \infty \quad &\text{if } \abs{\bm{r}_i - \bm{r}_j} \leq a
        \\
        0 \quad &\text{if } \abs{\bm{r}_i - \bm{r}_j} > a
    \end{cases}
\end{equation}

The Hamiltonian for a system of $N$ trapped atoms is then given by

\begin{equation}\label{eq:full_hamiltonian}
    H = - \frac{\hbar}{2m} \sum_{i=1}^{N} \grad^2_i + \sum_{i=1}^{N} V_\mathrm{trap}\qty(\bm{r}_i) + \sum_{i < j}^{N} V_\mathrm{int} \qty(\abs{\bm{r}_i - \bm{r}_j}),
\end{equation}

where the notation $i<j$ under the last summation sign signifies a double sum running over all pairwise interactions once. 

The trial wave function is chosen to take the form of a Slater-Jastrow wave function: 

\begin{equation}\label{eq:twf}
    \Psi_T (\bm{r}) = \Phi \qty(\bm{r}) J \qty(\bm{r}), 
\end{equation}

The Slater permanent, $\Phi \qty(\bm{r})$, is given by the first $N$ single-particle wave functions chosen to be proportional to the harmonic oscillator function for the ground state: 

\begin{equation}\label{eq:slater}
    \Phi \qty(\bm{r}) = \prod_i^N \phi \qty(\bm{r}_i) = \prod_i^N \mathrm{e}^{-\alpha \qty(x_i^2 + y_i^2 + \beta z_i^2)},
\end{equation}

where $\alpha$ and $\beta$ are variational parameters. For spherical traps we have $\beta = 1$ such that

\begin{equation}\label{eq:slater_spherical}
    \Phi \qty(\bm{r}) =  \prod_i^N \mathrm{e}^{-\alpha \abs{\bm{r}_i}^2} \quad \text{(S)}
\end{equation} 

The Jastrow correlation factor, $J(\bm{r})$, is chosen to be the exact solution of the SchrÃ¶dinger equation for interacting pairs of hard spheres atoms

\begin{equation}
    J \qty(\bm{r}) = \prod_{i<j}^N f \qty(a, \abs{\bm{r}_i - \bm{r}_j})
\end{equation}

where the correlation wave functions are given by
\begin{equation*}
    f \qty(a, \abs{\bm{r}_i - \bm{r}_j}) = 
    \begin{cases}
        0 \quad &\text{if } \abs{\bm{r}_i - \bm{r}_j} \leq a
        \\
        1 - \frac{a}{\abs{\bm{r}_i - \bm{r}_j}} \quad &\text{if } \abs{\bm{r}_i - \bm{r}_j} > a
    \end{cases}
\end{equation*}

For non-interacting bosons we have $a = 0$.

Useful relation: 

\begin{equation}\label{eq:slater_spherical}
    \prod_i^N \mathrm{e}^{-\alpha \abs{\bm{r}_i}^2} = \mathrm{e}^{-\alpha \sum_{i=1}^N \abs{\bm{r}_i}^2}
\end{equation} 


%----------------------------------------------------------------
\subsubsection*{Derivations}
%---------------------------------------------------------------- 

In the following derivations we will use natural units, i.e., $c = \hbar = m = 1$.

%----------------------------------------------------------------
\subsubsection*{Non-interacting, 1 particle}
%---------------------------------------------------------------- 

\textbf{Local Energy}

In the case of one particle trapped in a $d$ dimensional spherical harmonic oscillator potential ($\beta = 1$), the trial wave function is given by 

\begin{equation*}
    \Psi_T = \e^{-\alpha \abs{r}^2}
\end{equation*}

and the Hamiltonian by

\begin{equation*}
    H = - \frac{1}{2} \grad^2 + \frac{1}{2} \omega^2 r^2
\end{equation*}

Here, $r \in \R^d$ and $\grad^2$ is taken as the spherical Laplacian where the two radial derivative terms in $d$ dimensions are given by

\begin{equation*}
    \grad^2 = \frac{1}{r^{d-1}} \pdv{r} \qty(r^{d-1} \pdv{r})
\end{equation*}

Laplacian: 

\begin{align*}
    \grad^2 \Psi_T &= \frac{1}{r^{d-1}} \pdv{r} \qty(r^{d-1} \pdv{r} \e^{-\alpha \abs{r}^2})
    \\
    &= \frac{1}{r^{d-1}} \pdv{r} \qty(r^{d-1} \qty(- 2 \alpha r) \Psi_T)
    \\
    &= \frac{1}{r^{d-1}} \pdv{r} \qty(- 2 \alpha r^d \Psi_T)
    \\
    &= \frac{1}{r^{d-1}} \qty(-2d\alpha r^{d-1} \Psi_T + \qty(- 2 \alpha r^d)\qty(- 2 \alpha r) \Psi_T )
    \\
    &= \frac{1}{r^{d-1}} \qty(-2d \alpha r^{d-1} + 4 \alpha^2 r^{d+1}) \Psi_T
    \\
    &= \qty(-2d \alpha + 4 \alpha^2 r^2) \Psi_T
\end{align*}

Hamiltonian vs trial wf: 

\begin{align*}
    H \Psi_T &= \qty[ - \frac{1}{2} \qty(-2d \alpha + 4 \alpha^2 r^2) + \frac{1}{2} \omega^2 r^2] \Psi_T
    \\
    &= \qty[ d \alpha + r^2 \qty(\frac{1}{2} \omega^2 - 2 \alpha^2) ] \Psi_T
\end{align*}

Local energy: 

\begin{equation*}
    E_L = \frac{1}{\Psi_T} H \Psi_T = d \alpha + r^2 \qty(\frac{1}{2} \omega^2 - 2 \alpha^2),
\end{equation*}

where $r \in \R^d$.

\textbf{Drift Force}

\begin{equation*}
    F = \frac{2 \grad \Psi_T}{\Psi_T} = \frac{2 \pdv{r} \e^{-\alpha \abs{r}^2}}{\Psi_T} = \frac{2 \qty(-2 \alpha r) \Psi_T}{\Psi_T} = - 4 \alpha r
\end{equation*}

%----------------------------------------------------------------
\subsubsection*{Non-interacting,  N particles}
%---------------------------------------------------------------- 

\textbf{Local energy}

... 

\begin{equation*}
    E_L = N d \alpha + \sum_{i=1}^N r_i^2 \qty(\frac{1}{2} \omega^2 - 2 \alpha^2),
\end{equation*}

where $r_i \in \R^d$.

\textbf{Drift Force}

\begin{equation*}
    F = \frac{2 \grad \Psi_T}{\Psi_T} = \frac{2 \pdv{r} \qty( \prod_{i=1}^N \e^{-\alpha \abs{r_i}^2})}{\prod_{i=1}^N \e^{-\alpha \abs{r_i}^2}} = \frac{2 (-2 \alpha) \sum_{i=1}^N r_i \e^{-\alpha \abs{r_i}^2}}{\prod_{i=1}^N \e^{-\alpha \abs{r_i}^2}} = - 4 \alpha \sum_{i=1}^N r_i
\end{equation*}


%----------------------------------------------------------------
\subsubsection*{Optimization}
%---------------------------------------------------------------- 

\textbf{Gradient of expected value of local energy wrt $\alpha$}

...

Analytical expression: 
\begin{equation}\label{eq:grad_expval_E_L}
    \frac{\partial \expval{E_L[\mathbf{\alpha}]}}{\partial\mathbf{\alpha}} = 2\qty(\expval{\frac{d\Psi[\mathbf{\alpha}]}{d\mathbf{\alpha}}\frac{1}{\Psi[\mathbf{\alpha}]}E_L[\mathbf{\alpha}]} - \expval{\frac{d\Psi[\mathbf{\alpha}]}{d\mathbf{\alpha}}\frac{1}{\Psi[\mathbf{\alpha}]}}\expval{E_L[\mathbf{\alpha}})
\end{equation}


%----------------------------------------------------------------
\subsection*{Variational Monte Carlo}
%---------------------------------------------------------------- 

\textbf{Mathemical foundation of the Monte Carlo methods.}

The standard Monte Carlo approximation of $\mathbb{E}[f(X)]$, for some random variable $X:\Omega\to\R$, and a continous function $f:\R\to\R$ is
\begin{equation}
    E_M[f](\omega)= \frac{1}{M}\sum_{m=1}^Mf(X_m(\omega)), \quad \omega\in\Omega
\end{equation}
where $M\in\mathbb{N}$, $X_1, \dots, X_m$ are independent and identically distributed random varibles distributed with $X$. For definitions of indepent and identically distributed random variables, see appendix \ref{app:stochastic_maths}. We denote the standard deviation of the stochastic variable $f(X)$ as $\sigma_f$. The mean square error of the Monte Carlo approximation can be shown (shown in \ref{app:MC_error}) to be 
\begin{equation}
    \mathcal{E}_M(f) = \frac{\sigma_f}{\sqrt{M}}. 
\end{equation}
As $M\to\infty$, the error $\epsilon_M$ will therefore approach zero.

\textbf{The Variational Principle.}

Given a Hamiltonian $H$ and a trial wave function $\Psi_T$, the variational principle states that the expectation value $\expval{H}$, defined through
\begin{equation}
    \mathbb{E}[H]=\expval{H}= \frac{\int d\mathbf{R}\Psi_T^*(\mathbf{R})H(\mathbf{R})\Psi_T(\mathbf{R})}{\int d\mathbf{R}\Psi_T^*(\mathbf{R})\Psi_T(\mathbf{R})}, 
\end{equation}
is an upper bound tho the ground state energy $E_0$ of the Hamiltonian $\hat{H}$, that is 
\begin{equation}
    E_0 \leq \expval{H}.
\end{equation}
The eigenstates, $\psi_i$, of the Hamiltonian,
\begin{equation}
    H\psi_i(\mathbf{R}) = E_i\psi_i(\mathbf{R}), 
\end{equation}
form a complete set. The trial wave function can therefore be expanded in terms of them,
\begin{equation}
    \Psi_T(\mathbf{R}) = \sum_i a_i\Psi_i(\mathbf{R}), 
\end{equation}
and assuming the set of eigenfunctions to be normalized we obtain
\begin{equation}
    \frac{\sum_{nm}a_m^*a_n\int d\mathbf{R}\Psi_m^*(\mathbf{R})H(\mathbf{R})\Psi_n(\mathbf{R})}{\sum_{nm}a_m^*a_n\int d\mathbf{R}\Psi_m^*(\mathbf{R})\Psi_n(\mathbf{R})} = \frac{\sum_n a_n^2E_n}{\sum_n a_n^2} \geq E_0, 
\end{equation}
and the equality holds only if $\Psi_T = \psi_0$. Thus, the variational principle states that the lowest expectation value is our best approximation to the ground state. We utilise this by making a wave function that has a number of variational parameters, and search for a minimum in the space of the variational parameters. Note also that the moments of the Hamiltonian becomes
\begin{equation}
    \expval{H^N} = \frac{\int d\mathbf{R}\Psi_T^*(\mathbf{R}, \mathbf{\alpha})H^N\Psi_T(\mathbf{R},\mathbf{\alpha})}{\int d\mathbf{R}\Psi_T^*(\mathbf{R}, \mathbf{\alpha})\Psi_T(\mathbf{R}, \mathbf{\alpha})} = E_0^N
\end{equation}
when $\Psi_T=\psi_0$. The variance, 
\begin{equation}
    \text{Var}[E] = \expval{H^2}-\expval{H}^2, 
\end{equation}
is therefore zero when the ground state is found. Variation is then performed by minimizing both energy and variance. 

\textbf{Markov Chain Monte Carlo.}

Markov Chain Monte Carlo (MCMC) uses a Markov Chain method to sample in configuration space. A Markov Chain is a decision process which is only dependent on the current state when deciding the new state of the system, not on any previous states. For many-dimensional configuration space (in our case we simulate $N$ particles in $d$ dimensions, which yields a $N\times d$ dimensional configuration space) homogeneous uniform random sampling in configuration space would require a very large number of samples to sufficiently map the expectation values. We therefore use a kind of Markov Chain process where we start at an initial position in configuration space and move according to a sampling rule which takes into account the probability densities at the current and proposed states. This way we will sample regions of configuration space that are interesting to us, and thus we will need fewer samples compared to the homogeneous uniform random sampling of the standard Monte Carlo method. 

\textbf{Metropolis algorithm.}

The Metropolis algorithm is a stochastic sampling algorithm that takes into account a current state $\Psi_T(\mathbf{R_i})\to\bra{\mathbf{R_i}, \alpha}$ and a proposed next state $\Psi_T(j)\to\bra{j}$. We denote the transition probability from state $\bra{i}$ to state $\bra{j}$ as $T_{i\to j}$, $\bra{j}$ to $\bra{i}$ as $T_{j\to i}$. We denote the respective acceptance probabilities $A_{i\to j}$ and $A_{j\to i}$. In normal Metropolis sampling we simply set the transition probabilities $T_{i\to j}:=T_{j\to i}$, and set the acceptance probabilities equal to the probability distribution function (PDF) at state $\bra{i}$ and $\bra{j}$. In our case the PDF at position $\mathbf{R}_i$ is
\begin{equation}
    P(\mathbf{R}_i, \mathbf{\alpha}) = \frac{|\Psi_T(\mathbf{R}_i, \mathbf{\alpha})|^2}{\int d\mathbf{R}|\Psi_T^(\mathbf{R}, \mathbf{\alpha})|^2}, 
\end{equation}
where $\mathbf{\alpha}$ is the variational parameters. In the Metropolis sampling algorithm, which there is a small pseudocode for in \ref{Metropolis}, we only need the ratio between the PDFs of the proposed and current states, and we therefore don't need to evaluate the normalization factor of the PDF. The ratio between the PDFs of states $\Psi_T(\mathbf{R}_{j}, \mathbf{\alpha})$ and $\Psi_T(\mathbf{R}_i, \mathbf{\alpha})$ is 
\begin{equation}
    \frac{P(\mathbf{R}_j, \mathbf{\alpha})}{P(\mathbf{R}_i)} = \frac{|\Psi_T(\mathbf{R}_j, \mathbf{\alpha})|^2}{|\Psi_T(\mathbf{R}_i, \mathbf{\alpha})|^2}.
\end{equation}


\begin{algorithm}
\caption{Metropolis sampling algorithm}\label{Metropolis}
\begin{algorithmic}[1]
\Procedure{Metropolis}{($\mathbf{R}_{\text{old}}, \mathbf{R}_{\text{new}}$)}\Comment{Takes in the old and new parameters.}
\State $P_T(\mathbf{R}_{\text{old}}, \mathbf{\alpha}) \gets |\Psi_T(\mathbf{R}_{\text{old}}, \mathbf{\alpha})|^2$
\State $P_T(\mathbf{R}_{\text{new}}, \mathbf{\alpha}) \gets |\Psi_T(\mathbf{R}_{\text{new}}, \mathbf{\alpha})|^2$
\State $P_{\text{acceptance}}\gets\frac{P_T(\mathbf{R}_{\text{new}}, \mathbf{\alpha})}{P_T(\mathbf{R}_{\text{old}}, \mathbf{\alpha})}$\Comment{Finds the acceptance rate, purely based on transition rates being equal.}
\State $r = \text{RNG}[0,1]$\Comment{Generate a random number between $0$ and $1$ from uniform distribution.}
\If{r<\text{min}(P_{\text{acceptance}}, 1)}
\State $\text{Accept move}$
\Else 
\State $\text{Reject move}$
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}



\begin{algorithm}
\caption{Markov Chain Monte Carlo(MCMC)}\label{MCMC}
\begin{algorithmic}[1]
\Procedure{MCMC}{($\text{Number of cycles(nCycles)}$)}
\State $\mathbf{R}_{\text{old}}\gets\text{Initialise system}$\Comment{Find initial state of the system.}
\State $\text{Define } P_T(\mathbf{R}, \mathbf{\alpha})$\Comment{Define how to measure the PDF.}
\State ($P_T(\mathbf{R}_{\text{old}}, \mathbf{\alpha}) \gets |\Psi_T(\mathbf{R}_{\text{old}}, \mathbf{\alpha})|^2$)\Comment{In our case, we use this.}
\algblockdefx{For}{EndFor}[1]{\textbf{for} #1 \textbf{to} \text{nCycles} \textbf{do}}{\textbf{end for}}
\For{$1$}{}
    \State $\mathbf{R}_{\text{new}} = \mathbf{R}_{\text{old}} + \text{RNG}$\Comment{Suggest new position based on the old one, and add a randomly generated number (RNG).}
    \If{\mathbf{R}_{new} \text{ is accepted}}\Comment{Here we use a sampling rule to decide whether the stochastic move is accepted or rejected.}
        \State $\text{Update }\mathbf{R}_{old}\gets\mathbf{R}_{\text{new}}\text{ and collect data from new state.}$
    \Else
        \State $\text{Reject move and collect data from old state.}$
    \EndIf
\EndFor
\State $\text{Collect averages from collected data.}$
\EndProcedure
\end{algorithmic}
\end{algorithm}


