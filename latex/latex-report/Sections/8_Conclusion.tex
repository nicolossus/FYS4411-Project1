%================================================================
\section{Conclusion}\label{sec:Conclusion}
%================================================================

In this study we have investigated the variational Monte Carlo (VMC) method for estimating the ground state energy of an ultracold, dilute Bose gas in both a spherical and elliptical harmonic trap. We have used a trial wave function composed of a single particle Gaussian with a single variational parameter and a hard sphere Jastrow factor for pair correlations. We have built a VMC framework in Python with the Markov chain Monte Carlo sampling algorithms \textit{random walk Metropolis} (RWM) and \textit{Langevin Metropolis-Hastings} (LMH). The framework contained procedures for tuning the scale of the proposal distributions and gradient descent optimization of the variational parameter. Moreover, we also implemented automatic differentiation that can be applied to systems of non-interacting bosons. 

We found that the size of the statistical error of the variational energy found with the RWM algorithm is larger than for the LMH algorithm, given the same number of energy samples. This means that the RWM algorithm is slower than the LMH in terms of the total number of MC cycles needed to achieve a result with similar uncertainty. The statistical errors in \autoref{fig:rwm_vs_lmh} demonstrate that LMH asymptotically mix considerably faster than RWM, and thus would need fewer samples to find the ground state energy of the system with a given precision. In order to achieve the same statistical error in the RWM, the number of samples needs to be considerably higher. The increased number of accepted proposals in LMH compared to RWM also decrease the correlation between the samples. However, in terms of computation time the RWM algorithm performs better than LMH, as each step of the algorithm is fast compared to LMH. \autoref{fig:runtime_comparison} shows that the computational cost of the LMH is, by a significant factor, larger than for RWM, which is due to the calculations of the gradients and Green's function in the step function. Taking both the accuracy, computational time and also the comparable convergence rates in \autoref{fig:alpha_epoch_both} into account, the LMH algorithm seems to be the better choice of the two sampling algorithms in terms of computational efficiency for estimation of expectation values. 

We were successful in employing automatic differentiation to the system of non-interacting bosons. This comes at a significant computational cost, as illustrated by \autoref{fig:runtime_comparison}, but the advantage is that it mitigates the need for closed-form expressions. 



We found the analytical ground state of the non-interacting boson system to be $\frac{3}{2}\hbar\omega_{\mathrm{ho}}$ for the sperical trap, and $2.414215\hbar\omega_{\mathrm{ho}}$ for the elliptical trap. When the interactions simulated by the Jastrow correlation factor were included, we found an increase in the energy per particle proportional to the particle density. We calculated energies for three interacting system sizes, $N=\qty[10, 50, 100]$, and found the ground state energies per particle for the elliptical systems to be $\qty(2.446\pm 0.001)\hbar\omega_{\mathrm{ho}}$,$\qty(2.56\pm 0.02)\hbar\omega_{\mathrm{ho}}$, $\qty(2.68\pm 0.06)\hbar\omega_{\mathrm{ho}}$, respectively. For the spherical systems we found there to be similar increases in energy due to interactions of the particles, and they are tabulated in \autoref{tab:min_energies}.

The one-body densities reveal that, when the bosons are interacting, the state of the system is dependent on the density of bosons in the trap. One should think that when the interacting particles are close to one another, they interact with more frequency and strength, thus having a larger impact on the system state. If the interactions between the bosons are attractive, we therefore expect to observe a narrowing of the one-body density, and a spreading if the interactions were repulsive. We observe in \autoref{fig:one_body_densities} that the one-body density is more spread out in configuration space, which corresponds to repulsive interactions, and an increase in the spread as a function of the density. 

%The plotted statistical error in \autoref{fig:rwm_vs_lmh} demonstrates that LMH asmptotically mix considerably faster than RWM, and thus would need fewer samples to find the ground state energy of the system with a given precision. The increased number of accepted proposals in LMH compared with RWM decrease the correlation between the samples. 
%We observe in \autoref{fig:runtime_comparison} that the computational cost of the LMH is, by a significant factor, larger than for RWM, which is due to the calculations of the gradients and Green's function in the step function. Still, the statistical error for LMH is of a factor lower compared with RWM such that to achieve the same statistical error in the RWM, the number of samples needs to be considerably higher. Therefore, and together with the comparable convergence rates in \autoref{fig:alpha_epoch_both}, make us conclude that the LMH sampler is computationally more efficient in properly assessing the expectation values. 



%Concluding, we observe that the statistical error using the RWM is larger than for LMH when there is an equal number of samples. In fact, we see that the statistical error in the sampling is very much lower. However, our implementation also depends on the convergence to the right $\alpha$, and the standard error of the mean of the energy samples in \autoref{fig:rwm_vs_lmh}

%RWM is slow in terms of the total number of MC cycles, but each step is fast as it does not require gradients of the density. LMH on the other hand is faster in terms of the total number of MC cycles, but each step is slow as it uses gradients of the density at each step. Even taking the slowness of each step of LMH, it outperforms RWM. To achieve the same level of statistical error, the number of samples needed for the RWM would have to be much higher than the LMH. 

%Dette burde også med på en eller annen måte: The one-body densities reveal ...



% Kan vi si noe om korrelasjon mellom samples LMH vs RWM? Blocking burde gi en pekepinn
% Hmm, sier du at korrelasjonen mellom dem går ned eller opp? Den skal vel i prinsippet gå opp i LMH, siden den ikke bare tar utgangspunkt i posisjonen ved forrige tidssteg, men også F(r), i kontrast til RWM som bare tar utgangspunkt i posisjonene ved forrige tidssteg? 

% Man vil helst ha ukorrelerte samples, og selvom LMH har flere deler som avhenger av forrige state er det ikke nødvendigvis slik at den genererer mer korrelerte samples. Men tror egentlig vi ikke har noen figur eller måling som viser dette tydelig, så det kan kanskje være noe å nevne for fremtidig research
% Okay, acceptance rate er mye høyere for LMH, så samples vil være mer ukorrelerte på grunn av det også. Et problem er at første figuren i appendiks viser egentlig at LMH er dårligere enn RWM til å estimere gradienten. Eller kanskje ikke dårligere, kanskje bare gradienten egentlig er så stor for alpha<0.5. 

% Et litt subtilt poeng som ikke kommer frem av den figuren er jo at den kun viser en statisisk trial. Kjører man den på nytt kunne figurene fort blitt reversert. Poenget med den er nok snarere at når det gjelder optimize har det ikke noe å si om man bruker RWM eller LMH, som også gir mening så lenge begge har optimal scale som leder den mot stationary state effektivt 

% Ah, ja, det er et godt poeng. Så det er 1 thread, ikke 16 per alpha. Okay. ja. Kom ikke så langt at jeg fikk skrevet det, men tolkningen av de er altså 1 stokastisk forsøk, men de viser jo en trend 

% Kunne evt laget en figur som viser hvordan det blir når alle starter på samme alpha

% På ett vis viser vi jo konvergens mot rette alpha? Ut fra figuren tror jeg nok at du har rett i at sammenlignen mellom RWM og LMH viser at når den stasjonære tilstanden er funnet, så er det hipp som happ hvilken vi velger? Jeg kan sette i gang en kjøring med 4 threads per alpha og plotte RWM mot LMH i samme plott, hvis du tenker det er lurt? Kan gjøre det med 16 nå. har skriptet mer eller mindre klart. Okay, jeg tenkte litt med hensyn på første linje i konklusjonen over her: Den erroren vi får er en større error i konvergens mot rett alpha enn det er i statistical error. Blir det feil? Skal se på det snart